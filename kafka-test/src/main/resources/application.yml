server:
  port: 8283
spring:
  application:
    name: kafka-demo
  kafka:
    bootstrap-servers: 192.168.147.133:9092 #指定kafka server的地址，集群配置多个，中间逗号隔开
    #---------------------生产者配置文件-----------------
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      #设置等待acks返回的机制，有三个值
      #0：不等待返回的acks(可能会丢失数据，因为发送消息没有了失败重试机制，但是这是最低延迟)
      #1:消息发送给kafka分区中的leader后就返回（如果follower没有同步完成leader就宕机了，就会丢失数据）
      #-1：（默认） 等待所以的follower同步消息后再发送（绝对不会丢失数据）
      acks: -1
      #消息累积到batch-size的值后才会发送消息，默认为16384
      batch-size: 16384
      #如果kafka迟迟不发送消息（这里指的是消息没堆积到指定数量），那么过了这个时间（单位毫秒）开始发送
      properties:
        linger:
          ms: 1
      #设置缓冲区大小，默认是33554432
      #这个缓冲区是kafka中两个线程里的共享变量
      #这两个线程是main和sender,main负责把消息发送到共享变量，sender从共享变量拉数据
      buffer-memory: 33554432
      #失败重发的次数
      retries: 2
    #---------------------消费者配置文件-------------------
    consumer:
      group-id: default_consumer_group #群组id
      #kafka意外宕机，再次开启消息消费的策略，共有三种策略
      #earliest:当各分区下已有提交的offset时，从提交的offset开始消费，无提交的offset时，从头开始消费
      #latest:当各分区下已有提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      #none:当所有分区都存在提交的offset时，从offset后开时消费；只有有一个分区不存在已经提交的offset，则抛出异常
      auto-offset-reset: earliest
      #自动提交offset
      enable-auto-commit: true
      #提交offset时间间隔
      auto-commit-interval: 100
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer

